#!/usr/bin/python
# -*- coding: UTF-8 -*-

import numpy
from sklearn.cross_validation import train_test_split
from sklearn import ensemble
from sklearn.metrics import mean_squared_error
import pylab as plot
import xlrd
fname = "dxc.xlsx"
bk = xlrd.open_workbook(fname)
sh = bk.sheet_by_name("Sheet1")
nrows=sh.nrows
ncols=sh.ncols
print "nrows %d, ncols %d" % (nrows,ncols)

row_list=[]
for i in range(0,nrows):
    row_data=sh.row_values(i)
    row_list.append(row_data)
xList = []
labels = []
names = []
firstLine = True
for line in row_list:
    if firstLine:
        names = line
        firstLine = False
    else:
        row = line
        labels.append(float(row[-1]))
        row.pop()
        floatRow = [float(num) for num in row]
        xList.append(floatRow)

nrows = len(xList)
ncols = len(xList[0])

X = numpy.array(xList)
y = numpy.array(labels)
wineNames = numpy.array(names)
nEst = 2000
depth = None
learnRate = 0.01
subSamp = 1
wineGBMModel = ensemble.GradientBoostingRegressor(n_estimators=nEst,
                                                  max_depth=depth,
                                                  learning_rate=learnRate,
                                                  subsample = subSamp,
                                                  loss='ls')

wineGBMModel.fit(X, y)

msError = []
predictions = wineGBMModel.staged_predict(X)
m=[]
for p in predictions:
    msError.append(mean_squared_error(y, p))
    m.append(p)
print("MSE" )
print(min(msError))
print(msError.index(min(msError)))
print m[1543]

n=m[1543]
numpy.savetxt("dxc.txt", n)

结果：
MSE
9.99790557957e-08
1543
[ 2519.9992718   1100.00016981  1840.99958834 ...,  1190.99964838
   867.00055136  1029.0004812 ]